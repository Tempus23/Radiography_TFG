{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.config import *\n",
    "from src.data import *\n",
    "from src.models.efficientnet import EfficientNetB5Custom\n",
    "from src.utils import *\n",
    "from src.data import OriginalOAIDataset\n",
    "from src.train import train, train_model\n",
    "from src.trainers.classification import Classification\n",
    "\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = MENDELEY_OAI_224_SPLIT_PATH\n",
    "NEW_DATASET_PATH = 'dataset/mendeleyOAI_dataset/brightness_200'\n",
    "def calculate_brightness(image):\n",
    "    \"\"\"\n",
    "    Calcula el brillo promedio de una imagen.\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    brightness = hsv[:, :, 2].mean()\n",
    "    return brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase: 0, Imágenes brillantes: 2201/2286, 96.28%\n",
      "Clase: 1, Imágenes brillantes: 1007/1046, 96.27%\n",
      "Clase: 2, Imágenes brillantes: 1426/1516, 94.06%\n",
      "Clase: 3, Imágenes brillantes: 700/757, 92.47%\n",
      "Clase: 4, Imágenes brillantes: 159/173, 91.91%\n",
      "Imágenes brillantes: 5493/5778, 95.07%\n",
      "Clase: 0, Imágenes brillantes: 306/328, 93.29%\n",
      "Clase: 1, Imágenes brillantes: 144/153, 94.12%\n",
      "Clase: 2, Imágenes brillantes: 204/212, 96.23%\n",
      "Clase: 3, Imágenes brillantes: 100/106, 94.34%\n",
      "Clase: 4, Imágenes brillantes: 20/27, 74.07%\n",
      "Imágenes brillantes: 6267/6604, 94.90%\n",
      "Clase: 0, Imágenes brillantes: 608/639, 95.15%\n",
      "Clase: 1, Imágenes brillantes: 281/296, 94.93%\n",
      "Clase: 2, Imágenes brillantes: 426/447, 95.30%\n",
      "Clase: 3, Imágenes brillantes: 198/223, 88.79%\n",
      "Clase: 4, Imágenes brillantes: 46/51, 90.20%\n",
      "Imágenes brillantes: 7826/8260, 94.75%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "BRIGHTNESS_THRESHOLD = 200\n",
    "\n",
    "n_imagenes = 0\n",
    "n_total_imagenes = 0\n",
    "imagenes_brillantes = 0\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_path = os.path.join(DATASET_PATH, split)\n",
    "    for class_name in os.listdir(split_path):\n",
    "        if not os.path.exists(NEW_DATASET_PATH + '/' + class_name):\n",
    "            os.makedirs(NEW_DATASET_PATH + '/' + class_name)\n",
    "        class_path = os.path.join(split_path, class_name)\n",
    "        total_images = len(os.listdir(class_path))\n",
    "        n_imagenes = 0\n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "            brightness = calculate_brightness(image)\n",
    "            if brightness < BRIGHTNESS_THRESHOLD:\n",
    "                cv2.imwrite(NEW_DATASET_PATH + '/' + class_name + '/' + image_name, image)\n",
    "                n_imagenes += 1\n",
    "        n_total_imagenes += total_images\n",
    "        imagenes_brillantes += n_imagenes\n",
    "        print(f'Clase: {class_name}, Imágenes brillantes: {n_imagenes}/{total_images}, {n_imagenes/total_images*100:.2f}%')\n",
    "    print(f'Imágenes brillantes: {imagenes_brillantes}/{n_total_imagenes}, {imagenes_brillantes/n_total_imagenes*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando split para la clase 0\n",
      "Train: 2180\n",
      "Val: 311\n",
      "Test: 624\n",
      "Generando split para la clase 1\n",
      "Train: 1002\n",
      "Val: 143\n",
      "Test: 287\n",
      "Generando split para la clase 2\n",
      "Train: 1439\n",
      "Val: 205\n",
      "Test: 412\n",
      "Generando split para la clase 3\n",
      "Train: 698\n",
      "Val: 99\n",
      "Test: 201\n",
      "Generando split para la clase 4\n",
      "Train: 157\n",
      "Val: 22\n",
      "Test: 46\n"
     ]
    }
   ],
   "source": [
    "NEW_DATASET_PATH = 'dataset/mendeleyOAI_dataset/brightness_200_split'\n",
    "classes = os.listdir(MENDELEY_OAI_BRIGHT_200)\n",
    "\n",
    "for c in classes:\n",
    "    class_dir = os.path.join(MENDELEY_OAI_BRIGHT_200, c)\n",
    "\n",
    "    images = os.listdir(class_dir)\n",
    "    n_images = len(images)\n",
    "    n_train = int(n_images * 0.7)\n",
    "    n_val = int(n_images * 0.1)\n",
    "    n_test = n_images - n_train - n_val\n",
    "\n",
    "    print(\"Generando split para la clase\", c)\n",
    "    print(\"Train:\", n_train)\n",
    "    print(\"Val:\", n_val)\n",
    "    print(\"Test:\", n_test)\n",
    "\n",
    "    train_images, val_test_images = train_test_split(images, test_size=n_val + n_test, random_state=RANDOM_SEED)\n",
    "    val_images, test_images = train_test_split(val_test_images, test_size=n_test, random_state=RANDOM_SEED)\n",
    "\n",
    "    if not os.path.exists(os.path.join(NEW_DATASET_PATH, 'train', c)):\n",
    "        os.makedirs(os.path.join(NEW_DATASET_PATH, 'train', c))\n",
    "    if not os.path.exists(os.path.join(NEW_DATASET_PATH, 'val', c)):\n",
    "        os.makedirs(os.path.join(NEW_DATASET_PATH, 'val', c))\n",
    "    if not os.path.exists(os.path.join(NEW_DATASET_PATH, 'test', c)):\n",
    "        os.makedirs(os.path.join(NEW_DATASET_PATH, 'test', c))\n",
    "        \n",
    "\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(class_dir, img), os.path.join(NEW_DATASET_PATH, 'train', c, img))\n",
    "    for img in val_images:\n",
    "        shutil.copy(os.path.join(class_dir, img), os.path.join(NEW_DATASET_PATH, 'val', c, img))\n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(class_dir, img), os.path.join(NEW_DATASET_PATH, 'test', c, img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ORIGINAL_TRAIN_PATH = os.path.join(MENDELEY_OAI_BRIGHT_200_SPLIT_PATH, 'train')\n",
    "ORIGINAL_VAL_PATH = os.path.join(MENDELEY_OAI_BRIGHT_200_SPLIT_PATH, 'val')\n",
    "ORIGINAL_TEST_PATH = os.path.join(MENDELEY_OAI_BRIGHT_200_SPLIT_PATH, 'test')\n",
    "classes = os.listdir(ORIGINAL_TRAIN_PATH)\n",
    "print(classes)\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "AUG_MENDELEY_OAI_BRIGHT_200_SPLIT_PATH = 'dataset/mendeleyOAI_dataset/brightness_200_split_aug_3k'\n",
    "\n",
    "\n",
    "NEW_TRAIN_PATH = os.path.join(AUG_MENDELEY_OAI_BRIGHT_200_SPLIT_PATH, 'train')\n",
    "NEW_VAL_PATH = os.path.join(AUG_MENDELEY_OAI_BRIGHT_200_SPLIT_PATH, 'val')\n",
    "NEW_TEST_PATH = os.path.join(AUG_MENDELEY_OAI_BRIGHT_200_SPLIT_PATH, 'test')\n",
    "\n",
    "# Create new directories\n",
    "if not os.path.exists(AUG_MENDELEY_OAI_BRIGHT_200_SPLIT_PATH):\n",
    "    os.makedirs(AUG_MENDELEY_OAI_BRIGHT_200_SPLIT_PATH)\n",
    "if not os.path.exists(NEW_TRAIN_PATH):\n",
    "    os.makedirs(NEW_TRAIN_PATH)\n",
    "if not os.path.exists(NEW_VAL_PATH):\n",
    "    os.makedirs(NEW_VAL_PATH)\n",
    "if not os.path.exists(NEW_TEST_PATH):\n",
    "    os.makedirs(NEW_TEST_PATH)\n",
    "for split in ['train', 'val', 'test']:\n",
    "    SPLIT_PATH = os.path.join(AUG_MENDELEY_OAI_BRIGHT_200_SPLIT_PATH, split)\n",
    "    for class_name in classes:\n",
    "        CLASS_PATH = os.path.join(SPLIT_PATH, class_name)\n",
    "        if not os.path.exists(CLASS_PATH):\n",
    "            os.makedirs(CLASS_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han copiado 2180 imágenes de la clase 0\n",
      "Augmenting 820 images for class 0\n",
      "Generando imágenes aumentadas para la clase 0...\n",
      "Probabilidad de que se genere una imagen aumentada: 0.4261467889908257\n",
      "Se han generado 3000 imágenes aumentadas para la clase 0\n",
      "-----------------------------------\n",
      "\n",
      "Se han copiado 1002 imágenes de la clase 1\n",
      "Augmenting 1998 images for class 1\n",
      "Generando imágenes aumentadas para la clase 1...\n",
      "Probabilidad de que se genere una imagen aumentada: 2.044011976047904\n",
      "Probabilidad de que se genere una imagen aumentada: 1.0979041916167664\n",
      "Probabilidad de que se genere una imagen aumentada: 0.22864271457085827\n",
      "Se han generado 3000 imágenes aumentadas para la clase 1\n",
      "-----------------------------------\n",
      "\n",
      "Se han copiado 1439 imágenes de la clase 2\n",
      "Augmenting 1561 images for class 2\n",
      "Generando imágenes aumentadas para la clase 2...\n",
      "Probabilidad de que se genere una imagen aumentada: 1.1347810979847117\n",
      "Probabilidad de que se genere una imagen aumentada: 0.20496872828353024\n",
      "Se han generado 3000 imágenes aumentadas para la clase 2\n",
      "-----------------------------------\n",
      "\n",
      "Se han copiado 698 imágenes de la clase 3\n",
      "Augmenting 2302 images for class 3\n",
      "Generando imágenes aumentadas para la clase 3...\n",
      "Probabilidad de que se genere una imagen aumentada: 3.347994269340974\n",
      "Probabilidad de que se genere una imagen aumentada: 2.379512893982808\n",
      "Probabilidad de que se genere una imagen aumentada: 1.4640401146131805\n",
      "Probabilidad de que se genere una imagen aumentada: 0.6330945558739255\n",
      "Probabilidad de que se genere una imagen aumentada: 0.11876790830945559\n",
      "Se han generado 3000 imágenes aumentadas para la clase 3\n",
      "-----------------------------------\n",
      "\n",
      "Se han copiado 157 imágenes de la clase 4\n",
      "Augmenting 2843 images for class 4\n",
      "Generando imágenes aumentadas para la clase 4...\n",
      "Probabilidad de que se genere una imagen aumentada: 18.158280254777072\n",
      "Probabilidad de que se genere una imagen aumentada: 17.16464968152866\n",
      "Probabilidad de que se genere una imagen aumentada: 16.190127388535032\n",
      "Probabilidad de que se genere una imagen aumentada: 15.23471337579618\n",
      "Probabilidad de que se genere una imagen aumentada: 14.298407643312103\n",
      "Probabilidad de que se genere una imagen aumentada: 13.387579617834396\n",
      "Probabilidad de que se genere una imagen aumentada: 12.502229299363059\n",
      "Probabilidad de que se genere una imagen aumentada: 11.58503184713376\n",
      "Probabilidad de que se genere una imagen aumentada: 10.712420382165606\n",
      "Probabilidad de que se genere una imagen aumentada: 9.814331210191083\n",
      "Probabilidad de que se genere una imagen aumentada: 8.922611464968153\n",
      "Probabilidad de que se genere una imagen aumentada: 8.043630573248407\n",
      "Probabilidad de que se genere una imagen aumentada: 7.234713375796178\n",
      "Probabilidad de que se genere una imagen aumentada: 6.3939490445859875\n",
      "Probabilidad de que se genere una imagen aumentada: 5.559554140127388\n",
      "Probabilidad de que se genere una imagen aumentada: 4.801592356687898\n",
      "Probabilidad de que se genere una imagen aumentada: 4.05\n",
      "Probabilidad de que se genere una imagen aumentada: 3.2410828025477705\n",
      "Probabilidad de que se genere una imagen aumentada: 2.4576433121019106\n",
      "Probabilidad de que se genere una imagen aumentada: 1.7315286624203823\n",
      "Probabilidad de que se genere una imagen aumentada: 0.9544585987261147\n",
      "Probabilidad de que se genere una imagen aumentada: 0.29203821656050954\n",
      "Se han generado 3000 imágenes aumentadas para la clase 4\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AUG_IMAGES = 3000\n",
    "for class_name in classes:\n",
    "    CLASS_PATH = os.path.join(NEW_TRAIN_PATH, class_name)\n",
    "    class_origin = os.path.join(ORIGINAL_TRAIN_PATH, class_name)\n",
    "    num_augmentations = AUG_IMAGES - len(os.listdir(class_origin))\n",
    "    \n",
    "\n",
    "    # Copy original images\n",
    "    for img_name in os.listdir(class_origin):\n",
    "        img_path = os.path.join(class_origin, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Verificar si la imagen fue leída correctamente\n",
    "        if img is None:\n",
    "            print(f\"Error al leer la imagen {img_path}. Puede que no sea una imagen válida o esté dañada.\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # Copiar la imagen\n",
    "        new_img_path = os.path.join(CLASS_PATH, f\"{class_name}_{img_name}\")\n",
    "        cv2.imwrite(new_img_path, img)\n",
    "\n",
    "    print(f\"Se han copiado {len(os.listdir(CLASS_PATH))} imágenes de la clase {class_name}\")\n",
    "    print(f'Augmenting {num_augmentations} images for class {class_name}')\n",
    "    print(f\"Generando imágenes aumentadas para la clase {class_name}...\")\n",
    "    \n",
    "    while(len(os.listdir(CLASS_PATH)) < AUG_IMAGES):\n",
    "        \n",
    "        probabilidad = ((AUG_IMAGES - len(os.listdir(CLASS_PATH))) / len(os.listdir(class_origin))) + 0.05\n",
    "        print(f\"Probabilidad de que se genere una imagen aumentada: {probabilidad}\")\n",
    "        for img_name in os.listdir(class_origin):\n",
    "            if len(os.listdir(CLASS_PATH)) >= AUG_IMAGES:\n",
    "                break\n",
    "            if np.random.rand() > probabilidad:\n",
    "                continue\n",
    "            \n",
    "            img_path = os.path.join(class_origin, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            img_array = img.reshape((1, ) + img.shape)\n",
    "            for batch in data_gen.flow(img_array, batch_size=1, save_to_dir=CLASS_PATH, save_prefix='aug', save_format='png'):\n",
    "                break\n",
    "            \n",
    "            \n",
    "\n",
    "    print(f\"Se han generado {len(os.listdir(CLASS_PATH))} imágenes aumentadas para la clase {class_name}\\n-----------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han copiado 311 imágenes de la clase 0\n",
      "Se han copiado 143 imágenes de la clase 1\n",
      "Se han copiado 205 imágenes de la clase 2\n",
      "Se han copiado 99 imágenes de la clase 3\n",
      "Se han copiado 22 imágenes de la clase 4\n",
      "Se han copiado 624 imágenes de la clase 0\n",
      "Se han copiado 287 imágenes de la clase 1\n",
      "Se han copiado 412 imágenes de la clase 2\n",
      "Se han copiado 201 imágenes de la clase 3\n",
      "Se han copiado 46 imágenes de la clase 4\n"
     ]
    }
   ],
   "source": [
    "for class_name in classes:\n",
    "    CLASS_PATH = os.path.join(NEW_VAL_PATH, class_name)\n",
    "    class_origin = os.path.join(ORIGINAL_VAL_PATH, class_name)\n",
    "    num_augmentations = 1000 - len(os.listdir(class_origin))\n",
    "    \n",
    "\n",
    "    # Copy original images\n",
    "    for img_name in os.listdir(class_origin):\n",
    "        img_path = os.path.join(class_origin, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Verificar si la imagen fue leída correctamente\n",
    "        if img is None:\n",
    "            print(f\"Error al leer la imagen {img_path}. Puede que no sea una imagen válida o esté dañada.\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # Copiar la imagen\n",
    "        new_img_path = os.path.join(CLASS_PATH, f\"{class_name}_{img_name}\")\n",
    "        cv2.imwrite(new_img_path, img)\n",
    "\n",
    "    print(f\"Se han copiado {len(os.listdir(CLASS_PATH))} imágenes de la clase {class_name}\")\n",
    "\n",
    "\n",
    "for class_name in classes:\n",
    "    CLASS_PATH = os.path.join(NEW_TEST_PATH, class_name)\n",
    "    class_origin = os.path.join(ORIGINAL_TEST_PATH, class_name)\n",
    "    num_augmentations = 1000 - len(os.listdir(class_origin))\n",
    "    \n",
    "\n",
    "    # Copy original images\n",
    "    for img_name in os.listdir(class_origin):\n",
    "        img_path = os.path.join(class_origin, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Verificar si la imagen fue leída correctamente\n",
    "        if img is None:\n",
    "            print(f\"Error al leer la imagen {img_path}. Puede que no sea una imagen válida o esté dañada.\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # Copiar la imagen\n",
    "        new_img_path = os.path.join(CLASS_PATH, f\"{class_name}_{img_name}\")\n",
    "        cv2.imwrite(new_img_path, img)\n",
    "\n",
    "    print(f\"Se han copiado {len(os.listdir(CLASS_PATH))} imágenes de la clase {class_name}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│ Clase   │    0 │    1 │    2 │    3 │    4 │\n",
      "╞═════════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│ train   │ 3000 │ 3000 │ 3000 │ 3000 │ 3000 │\n",
      "├─────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│ val     │  311 │  143 │  205 │   99 │   22 │\n",
      "├─────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│ test    │  624 │  287 │  412 │  201 │   46 │\n",
      "╘═════════╧══════╧══════╧══════╧══════╧══════╛\n"
     ]
    }
   ],
   "source": [
    "img = explorar_split_data(AUG_MENDELEY_OAI_BRIGHT_200_SPLIT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
