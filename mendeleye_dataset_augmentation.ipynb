{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.config import *\n",
    "from src.data import *\n",
    "from src.models.efficientnet import EfficientNetB5Custom\n",
    "from src.utils import *\n",
    "from src.data import OriginalOAIDataset\n",
    "from src.train import train, train_model\n",
    "from src.trainers.classification import Classification\n",
    "\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MENDELEY_EXPERT1_SPLIT_PATH\n",
    "AUG_MENDELEY_EXPERT1_SPLIT_PATH = 'dataset/mendeley_dataset/augmented_mendeley_expert1_split'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤═════╤═════╤═════╤═════╤═════╕\n",
      "│ Clase   │   0 │   1 │   2 │   3 │   4 │\n",
      "╞═════════╪═════╪═════╪═════╪═════╪═════╡\n",
      "│ train   │ 359 │ 333 │ 162 │ 154 │ 144 │\n",
      "├─────────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│ val     │  51 │  47 │  23 │  22 │  20 │\n",
      "├─────────┼─────┼─────┼─────┼─────┼─────┤\n",
      "│ test    │ 104 │  97 │  47 │  45 │  42 │\n",
      "╘═════════╧═════╧═════╧═════╧═════╧═════╛\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═════════╤══════╤══════╤══════╤══════╤══════╕\n",
      "│ Clase   │    0 │    1 │    2 │    3 │    4 │\n",
      "╞═════════╪══════╪══════╪══════╪══════╪══════╡\n",
      "│ train   │ 1000 │ 1000 │ 1000 │ 1000 │ 1000 │\n",
      "├─────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│ val     │   51 │   47 │   23 │   22 │   20 │\n",
      "├─────────┼──────┼──────┼──────┼──────┼──────┤\n",
      "│ test    │  104 │   97 │   47 │   45 │   42 │\n",
      "╘═════════╧══════╧══════╧══════╧══════╧══════╛\n"
     ]
    }
   ],
   "source": [
    "img = explorar_split_data(MENDELEY_EXPERT1_SPLIT_PATH)\n",
    "img = explorar_split_data(AUG_MENDELEY_EXPERT1_SPLIT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ORIGINAL_TRAIN_PATH = os.path.join(MENDELEY_EXPERT1_SPLIT_PATH, 'train')\n",
    "ORIGINAL_VAL_PATH = os.path.join(MENDELEY_EXPERT1_SPLIT_PATH, 'val')\n",
    "ORIGINAL_TEST_PATH = os.path.join(MENDELEY_EXPERT1_SPLIT_PATH, 'test')\n",
    "classes = os.listdir(ORIGINAL_TRAIN_PATH)\n",
    "print(classes)\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "NEW_TRAIN_PATH = os.path.join(AUG_MENDELEY_EXPERT1_SPLIT_PATH, 'train')\n",
    "NEW_VAL_PATH = os.path.join(AUG_MENDELEY_EXPERT1_SPLIT_PATH, 'val')\n",
    "NEW_TEST_PATH = os.path.join(AUG_MENDELEY_EXPERT1_SPLIT_PATH, 'test')\n",
    "\n",
    "# Create new directories\n",
    "if not os.path.exists(AUG_MENDELEY_EXPERT1_SPLIT_PATH):\n",
    "    os.makedirs(AUG_MENDELEY_EXPERT1_SPLIT_PATH)\n",
    "if not os.path.exists(NEW_TRAIN_PATH):\n",
    "    os.makedirs(NEW_TRAIN_PATH)\n",
    "if not os.path.exists(NEW_VAL_PATH):\n",
    "    os.makedirs(NEW_VAL_PATH)\n",
    "if not os.path.exists(NEW_TEST_PATH):\n",
    "    os.makedirs(NEW_TEST_PATH)\n",
    "for split in ['train', 'val', 'test']:\n",
    "    SPLIT_PATH = os.path.join(AUG_MENDELEY_EXPERT1_SPLIT_PATH, split)\n",
    "    for class_name in classes:\n",
    "        CLASS_PATH = os.path.join(SPLIT_PATH, class_name)\n",
    "        if not os.path.exists(CLASS_PATH):\n",
    "            os.makedirs(CLASS_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_name in classes:\n",
    "    CLASS_PATH = os.path.join(NEW_TRAIN_PATH, class_name)\n",
    "    class_origin = os.path.join(ORIGINAL_TRAIN_PATH, class_name)\n",
    "    num_augmentations = 1000 - len(os.listdir(class_origin))\n",
    "    \n",
    "\n",
    "    # Copy original images\n",
    "    for img_name in os.listdir(class_origin):\n",
    "        img_path = os.path.join(class_origin, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Verificar si la imagen fue leída correctamente\n",
    "        if img is None:\n",
    "            print(f\"Error al leer la imagen {img_path}. Puede que no sea una imagen válida o esté dañada.\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # Copiar la imagen\n",
    "        new_img_path = os.path.join(CLASS_PATH, f\"{class_name}_{img_name}\")\n",
    "        cv2.imwrite(new_img_path, img)\n",
    "\n",
    "    print(f\"Se han copiado {len(os.listdir(CLASS_PATH))} imágenes de la clase {class_name}\")\n",
    "    print(f'Augmenting {num_augmentations} images for class {class_name}')\n",
    "    print(f\"Generando imágenes aumentadas para la clase {class_name}...\")\n",
    "    \n",
    "    while(len(os.listdir(CLASS_PATH)) < 1000):\n",
    "        \n",
    "        probabilidad = ((1000 - len(os.listdir(CLASS_PATH))) / len(os.listdir(class_origin))) + 0.05\n",
    "        print(f\"Probabilidad de que se genere una imagen aumentada: {probabilidad}\")\n",
    "        for img_name in os.listdir(class_origin):\n",
    "            if len(os.listdir(CLASS_PATH)) >= 1000:\n",
    "                break\n",
    "            if np.random.rand() > probabilidad:\n",
    "                continue\n",
    "            \n",
    "            img_path = os.path.join(class_origin, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            img_array = img.reshape((1, ) + img.shape)\n",
    "            for batch in data_gen.flow(img_array, batch_size=1, save_to_dir=CLASS_PATH, save_prefix='aug', save_format='png'):\n",
    "                break\n",
    "            \n",
    "            \n",
    "\n",
    "    print(f\"Se han generado {len(os.listdir(CLASS_PATH))} imágenes aumentadas para la clase {class_name}\\n-----------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han copiado 51 imágenes de la clase 0\n",
      "Augmenting 949 images for class 0\n",
      "Generando imágenes aumentadas para la clase 0...\n",
      "Se han copiado 47 imágenes de la clase 1\n",
      "Augmenting 953 images for class 1\n",
      "Generando imágenes aumentadas para la clase 1...\n",
      "Se han copiado 23 imágenes de la clase 2\n",
      "Augmenting 977 images for class 2\n",
      "Generando imágenes aumentadas para la clase 2...\n",
      "Se han copiado 22 imágenes de la clase 3\n",
      "Augmenting 978 images for class 3\n",
      "Generando imágenes aumentadas para la clase 3...\n",
      "Se han copiado 20 imágenes de la clase 4\n",
      "Augmenting 980 images for class 4\n",
      "Generando imágenes aumentadas para la clase 4...\n"
     ]
    }
   ],
   "source": [
    "for class_name in classes:\n",
    "    CLASS_PATH = os.path.join(NEW_VAL_PATH, class_name)\n",
    "    class_origin = os.path.join(ORIGINAL_VAL_PATH, class_name)\n",
    "    num_augmentations = 1000 - len(os.listdir(class_origin))\n",
    "    \n",
    "\n",
    "    # Copy original images\n",
    "    for img_name in os.listdir(class_origin):\n",
    "        img_path = os.path.join(class_origin, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Verificar si la imagen fue leída correctamente\n",
    "        if img is None:\n",
    "            print(f\"Error al leer la imagen {img_path}. Puede que no sea una imagen válida o esté dañada.\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # Copiar la imagen\n",
    "        new_img_path = os.path.join(CLASS_PATH, f\"{class_name}_{img_name}\")\n",
    "        cv2.imwrite(new_img_path, img)\n",
    "\n",
    "    print(f\"Se han copiado {len(os.listdir(CLASS_PATH))} imágenes de la clase {class_name}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han copiado 104 imágenes de la clase 0\n",
      "Se han copiado 97 imágenes de la clase 1\n",
      "Se han copiado 47 imágenes de la clase 2\n",
      "Se han copiado 45 imágenes de la clase 3\n",
      "Se han copiado 42 imágenes de la clase 4\n"
     ]
    }
   ],
   "source": [
    "for class_name in classes:\n",
    "    CLASS_PATH = os.path.join(NEW_TEST_PATH, class_name)\n",
    "    class_origin = os.path.join(ORIGINAL_TEST_PATH, class_name)\n",
    "    num_augmentations = 1000 - len(os.listdir(class_origin))\n",
    "    \n",
    "\n",
    "    # Copy original images\n",
    "    for img_name in os.listdir(class_origin):\n",
    "        img_path = os.path.join(class_origin, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Verificar si la imagen fue leída correctamente\n",
    "        if img is None:\n",
    "            print(f\"Error al leer la imagen {img_path}. Puede que no sea una imagen válida o esté dañada.\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # Copiar la imagen\n",
    "        new_img_path = os.path.join(CLASS_PATH, f\"{class_name}_{img_name}\")\n",
    "        cv2.imwrite(new_img_path, img)\n",
    "\n",
    "    print(f\"Se han copiado {len(os.listdir(CLASS_PATH))} imágenes de la clase {class_name}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explorar_split_data(AUG_MENDELEY_EXPERT1_SPLIT_PATH)\n",
    "mostrar_imagenes(AUG_MENDELEY_EXPERT1_SPLIT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
