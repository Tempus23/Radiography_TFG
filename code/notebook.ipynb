{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "#from data import loader_train, loader_val, loader_test\n",
    "from train import train_model, test_model\n",
    "from models import getModels\n",
    "from utils import show_img\n",
    "from trainers import Regression, Classification, BinaryClassification\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from ResNet18 import ResNet, BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\34658\\.medmnist\\dermamnist_224.npz\n",
      "Using downloaded and verified file: C:\\Users\\34658\\.medmnist\\dermamnist_224.npz\n",
      "Using downloaded and verified file: C:\\Users\\34658\\.medmnist\\dermamnist_224.npz\n"
     ]
    }
   ],
   "source": [
    "from medmnist import PneumoniaMNIST, BreastMNIST, RetinaMNIST, DermaMNIST, ChestMNIST, PathMNIST\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "batch_size = 128\n",
    "transfomrms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_dataset = DermaMNIST(split=\"test\",transform= transfomrms, download=True,size=224)\n",
    "train_dataset = DermaMNIST(split=\"train\", transform= transfomrms,download=True,size=224)\n",
    "val_dataset = DermaMNIST(split=\"val\",transform=transfomrms, download=True,size=224)\n",
    "\n",
    "loader_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "loader_val = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# Definir el tamaño del subconjunto que deseas usar (por ejemplo, 10%)\n",
    "subset_size = int(0.1 * len(train_dataset))\n",
    "\n",
    "# Crear subconjuntos con índices aleatorios\n",
    "train_indices = torch.randperm(len(train_dataset))[:subset_size]\n",
    "val_indices = torch.randperm(len(val_dataset))[:subset_size*2]\n",
    "test_indices = torch.randperm(len(test_dataset))[:subset_size*2]\n",
    "\n",
    "# Crear los subconjuntos utilizando los índices seleccionados\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "val_subset = Subset(val_dataset, val_indices)\n",
    "test_subset = Subset(test_dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: chermar (chermar-universitat-polit-cnica-de-val-ncia). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34658\\OneDrive\\Escritorio\\Ing informática\\Cuarto\\TFG\\KneeIA_Humans\\IA_KneeXRay\\code\\wandb\\run-20241101_183725-3r6tqhti</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/Test/runs/3r6tqhti' target=\"_blank\">MyComputer - Tests</a></strong> to <a href='https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/Test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/Test' target=\"_blank\">https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/Test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/Test/runs/3r6tqhti' target=\"_blank\">https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/Test/runs/3r6tqhti</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/Test/runs/3r6tqhti?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1b7886b2320>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start a new wandb run to track this script\n",
    "import wandb\n",
    "wandb.finish()\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Test\",\n",
    "    name=\"MyComputer - Tests\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"N_images\" : 1,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"dataset\": \"Expert 1\",\n",
    "        \"epochs\": 50,\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "loader_train = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "loader_val = DataLoader(val_dataset, batch_size=32, shuffle=True)\n",
    "loader_test = DataLoader(test_subset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics as tm\n",
    "from torchmetrics.classification import MulticlassConfusionMatrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Classification(pl.LightningModule):\n",
    "    def __init__(self, model, device):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=(\"model\",))\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.confusion_matrix = MulticlassConfusionMatrix(num_classes=self.model.classes).to(device)\n",
    "        self.auc_metric = tm.AUROC(num_classes=self.model.classes, task=\"multiclass\").to(device)  # Definir métrica AUROC para clasificación multiclase\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, x, y):\n",
    "        y_hat = self.model(x)\n",
    "        y_hot = self.transform_classes(y)\n",
    "        loss = self.loss_fn(y_hat, y_hot.squeeze())\n",
    "        # Obtener la clase predicha\n",
    "        y_pred = torch.argmax(y_hat, dim=1)\n",
    "        # Calcular métricas\n",
    "        loss.backward()\n",
    "        self.confusion_matrix.update(y_pred, y.squeeze())\n",
    "        self.auc_metric(y_hat, y_hot)\n",
    "\n",
    "        precision, recall, f1_score, ACC, AUC = self.calculate_metrics_from_confusion_matrix()\n",
    "\n",
    "        return {\"loss\": loss, \"ACC\": ACC, \"recall\": recall, \"precision\": precision, \"f1_score\": f1_score, \"AUC\": AUC}\n",
    "\n",
    "    def validation_step(self, x, y):\n",
    "        y_hat = self.model(x)\n",
    "        y = self.transform_classes(y)\n",
    "        loss = self.loss_fn(y_hat, y.squeeze())\n",
    "        # Obtener la clase predicha\n",
    "        y_pred = torch.argmax(y_hat, dim=1)\n",
    "\n",
    "        # Calcular métricas\n",
    "        self.confusion_matrix.update(y_pred, y)\n",
    "\n",
    "        precision, recall, f1_score, ACC, AUC = self.calculate_metrics_from_confusion_matrix()\n",
    "\n",
    "        return {\"loss\": loss, \"ACC\": ACC, \"precision\" : precision, \"recall\": recall, \"f1_score\" : f1_score, \"AUC\": AUC}\n",
    "    def calculate_metrics_from_confusion_matrix(self):\n",
    "      confusion_matrix = self.confusion_matrix.compute()\n",
    "      # Verdaderos positivos por clase (diagonal de la matriz)\n",
    "      true_positives = torch.diag(confusion_matrix)\n",
    "\n",
    "      # Predicciones totales por clase (sumar columnas)\n",
    "      predicted_positives = confusion_matrix.sum(dim=0)\n",
    "\n",
    "      # Ejemplos reales por clase (sumar filas)\n",
    "      actual_positives = confusion_matrix.sum(dim=1)\n",
    "\n",
    "      # Calcular Precision, Recall, F1 por clase\n",
    "      precision = (true_positives / (predicted_positives + 1e-8)).mean()  # Añadir pequeña constante para evitar división por 0\n",
    "      recall = (true_positives / (actual_positives + 1e-8)).mean()\n",
    "      f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "      # Calcular ACC\n",
    "      ACC = true_positives.sum() / confusion_matrix.sum()\n",
    "\n",
    "      # Calcular el AUC\n",
    "      AUC = self.auc_metric.compute()\n",
    "      # Retornar las métricas\n",
    "      return precision, recall, f1, ACC, AUC\n",
    "    def transform_classes(self, y):\n",
    "        # Convertir las clases a un formato de one-hot encoding\n",
    "        return torch.nn.functional.one_hot(y.to(torch.int64), num_classes=self.model.classes).to(float)\n",
    "    def restart_epoch(self, plot = False):\n",
    "        if plot:\n",
    "            self.confusion_matrix.plot()\n",
    "            plt.show()\n",
    "        self.confusion_matrix.reset()\n",
    "        self.auc_metric.reset()\n",
    "    def configure_optimizers(self, learning_rate=0.001, betas=(0.9, 0.999), factor=0.1, patience=5):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(),\n",
    "                                     lr=learning_rate,\n",
    "                                     betas=betas)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                               factor=factor,\n",
    "                                                               patience=patience)\n",
    "        return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m  ResNet(img_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, num_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m18\u001b[39m, block\u001b[38;5;241m=\u001b[39mBasicBlock, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m      8\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Classification(model, device)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[64], line 26\u001b[0m, in \u001b[0;36mClassification.training_step\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     24\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[0;32m     25\u001b[0m y_hot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_classes(y)\n\u001b[1;32m---> 26\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_hot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Obtener la clase predicha\u001b[39;00m\n\u001b[0;32m     28\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(y_hat, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\34658\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\34658\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\34658\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\34658\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "import torchmetrics as tm\n",
    "from torch import nn\n",
    "\n",
    "batch = next(iter(loader_train))\n",
    "x , y = batch\n",
    "device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model =  ResNet(img_channels=3, num_layers=18, block=BasicBlock, num_classes=7)\n",
    "trainer = Classification(model, device)\n",
    "\n",
    "trainer.training_step(x, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 1., 0.], dtype=torch.float64) tensor([ 0.0071, -0.4821,  0.0485,  0.3912, -0.5942,  0.2623,  0.1378],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Either `preds` and `target` both should have the (same) shape (N, ...), or `target` should be (N, ...) and `preds` should be (N, C, ...).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Classification(model, device)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m test_model(model, loader_test, trainer, device, classification \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\34658\\OneDrive\\Escritorio\\Ing informática\\Cuarto\\TFG\\KneeIA_Humans\\IA_KneeXRay\\code\\train.py:39\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, trainer, device, num_epochs, classification, learning_rate, betas, factor, patience)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 39\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m         loss \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     41\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[47], line 32\u001b[0m, in \u001b[0;36mClassification.training_step\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Calcular métricas\u001b[39;00m\n\u001b[0;32m     31\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfusion_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m precision, recall, f1_score, ACC, AUC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_metrics_from_confusion_matrix()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACC\u001b[39m\u001b[38;5;124m\"\u001b[39m: ACC, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m: recall, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m: precision, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1_score, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m\"\u001b[39m: AUC}\n",
      "File \u001b[1;32mc:\\Users\\34658\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\metric.py:482\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 482\u001b[0m         update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    484\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[1;32mc:\\Users\\34658\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\classification\\confusion_matrix.py:283\u001b[0m, in \u001b[0;36mMulticlassConfusionMatrix.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_args:\n\u001b[1;32m--> 283\u001b[0m     \u001b[43m_multiclass_confusion_matrix_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    284\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _multiclass_confusion_matrix_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index)\n\u001b[0;32m    285\u001b[0m confmat \u001b[38;5;241m=\u001b[39m _multiclass_confusion_matrix_update(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes)\n",
      "File \u001b[1;32mc:\\Users\\34658\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchmetrics\\functional\\classification\\confusion_matrix.py:283\u001b[0m, in \u001b[0;36m_multiclass_confusion_matrix_tensor_validation\u001b[1;34m(preds, target, num_classes, ignore_index)\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `preds` and `target` should have the same shape,\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    280\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m got `preds` with shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreds\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and `target` with shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    281\u001b[0m         )\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither `preds` and `target` both should have the (same) shape (N, ...), or `target` should be (N, ...)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and `preds` should be (N, C, ...).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m     )\n\u001b[0;32m    288\u001b[0m check_value \u001b[38;5;241m=\u001b[39m num_classes \u001b[38;5;28;01mif\u001b[39;00m ignore_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_classes \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, name \u001b[38;5;129;01min\u001b[39;00m ((target, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m),) \u001b[38;5;241m+\u001b[39m ((preds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m\"\u001b[39m),) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;28;01melse\u001b[39;00m ():  \u001b[38;5;66;03m# noqa: RUF005\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Either `preds` and `target` both should have the (same) shape (N, ...), or `target` should be (N, ...) and `preds` should be (N, C, ...)."
     ]
    }
   ],
   "source": [
    "#train a model\n",
    "model =  ResNet(img_channels=3, num_layers=18, block=BasicBlock, num_classes=7)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainer = Classification(model, device)\n",
    "\n",
    "\n",
    "\n",
    "train_model(model, loader_train, loader_val, trainer,  device, num_epochs=2, classification = True)\n",
    "test_model(model, loader_test, trainer, device, classification = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
