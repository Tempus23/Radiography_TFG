{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paper\n",
    "## Imports\n",
    "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10863523\n",
    "\n",
    "bib reference -> 10863523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "\n",
    "from src.config import *\n",
    "from src.data import *\n",
    "from src.models.efficientnet import EfficientNetB5Custom\n",
    "from src.utils import *\n",
    "from src.data import OriginalOAIDataset\n",
    "from src.train import train, train_model\n",
    "from src.trainers.classification import Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_OAI_DATASET = 'dataset/mendeleyOAI_dataset/augmented_dataset_1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset\n",
    "data = explorar_split_data(MENDELEY_OAI_224_SPLIT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_TRAIN_PATH = os.path.join(MENDELEY_OAI_224_SPLIT_PATH, 'train')\n",
    "classes = [d for d in os.listdir(ORIGINAL_TRAIN_PATH) if os.path.isdir(os.path.join(ORIGINAL_TRAIN_PATH, d))]\n",
    "data_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "if not os.path.exists(NEW_OAI_DATASET):\n",
    "    os.makedirs(NEW_OAI_DATASET)\n",
    "\n",
    "augmentation_classes = [1, 2, 5, 10, 20]\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(ORIGINAL_TRAIN_PATH, class_name)\n",
    "    print(int(class_name))\n",
    "    num_augmentations = augmentation_classes[int(class_name)]\n",
    "    print(f\"Generando imágenes aumentadas para la clase {class_name}...\")\n",
    "    print(f\"Se generarán {num_augmentations} imágenes\")\n",
    "    print(f\"Directorio original de la clase: {class_dir}\")\n",
    "    imagenes_generadas = 0\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        \n",
    "        \n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        # Verificar si la imagen fue leída correctamente\n",
    "        if img is None:\n",
    "            print(f\"Error al leer la imagen {img_path}. Puede que no sea una imagen válida o esté dañada.\")\n",
    "            continue\n",
    "        \n",
    "        # Convertir la imagen a un numpy array\n",
    "        img_array = np.array(img)\n",
    "        img_array = img_array.reshape((1,) + img_array.shape)  # Añadir dimensión batch\n",
    "        # Generar imágenes aumentadas\n",
    "        \"\"\"\n",
    "        for i in range(num_augmentations):\n",
    "            for batch in data_gen.flow(img_array, batch_size=1, save_to_dir=NEW_OAI_DATASET, save_prefix='aug', save_format='png'):\n",
    "                break\n",
    "        \"\"\"\n",
    "        imagenes_generadas += num_augmentations\n",
    "\n",
    "    print(f\"Se han generado {imagenes_generadas} imágenes aumentadas para la clase {class_name}\\n-----------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOCAL MODE ENABLED\n",
      "LOCAL MODE ENABLED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\34658\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\34658\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B5_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B5_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "BATCH_SIZE = 20\n",
    "LEARNING_RATE = 0.001\n",
    "FACTOR = 0.001\n",
    "L1 = 0.001\n",
    "L2 = 0.001\n",
    "PATIENCE = 5\n",
    "BETAS=(0.9, 0.999)\n",
    "# Regularización L1 y L2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_dataset = OriginalOAIDataset('train', batch_size=BATCH_SIZE, transform=transform, local=True)\n",
    "val_dataset = OriginalOAIDataset('val', batch_size=BATCH_SIZE, transform=transform, local=True)\n",
    "model = EfficientNetB5Custom(num_classes = 5)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainer = Classification(model, device, L1=L1, L2=L2, lr=LEARNING_RATE, factor=FACTOR, patience=PATIENCE, betas=BETAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:7xtjdn4j) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a718b16a0e3c43d8acf9fe207ff2f5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Test</strong> at: <a href='https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/oai-knee-cartilage-segmentation/runs/7xtjdn4j' target=\"_blank\">https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/oai-knee-cartilage-segmentation/runs/7xtjdn4j</a><br/> View project at: <a href='https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/oai-knee-cartilage-segmentation' target=\"_blank\">https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/oai-knee-cartilage-segmentation</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250216_185642-7xtjdn4j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:7xtjdn4j). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412dc0802eae4e758c017199a88c854a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\34658\\OneDrive\\Escritorio\\Ing informática\\TFG\\Radiography_TFG\\wandb\\run-20250216_185714-mbi7a47f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/oai-knee-cartilage-segmentation/runs/mbi7a47f' target=\"_blank\">Test</a></strong> to <a href='https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/oai-knee-cartilage-segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/oai-knee-cartilage-segmentation' target=\"_blank\">https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/oai-knee-cartilage-segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/oai-knee-cartilage-segmentation/runs/mbi7a47f' target=\"_blank\">https://wandb.ai/chermar-universitat-polit-cnica-de-val-ncia/oai-knee-cartilage-segmentation/runs/mbi7a47f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch [1/2]: 100%|█| 25/25 [07:04<00:00, 16.96s/it, curr_train_loss=1116.19480675, val_loss\n",
      "Validation Epoch [1/2]: 100%|██████████████████| 22/22 [01:43<00:00,  4.71s/it, val_loss=1.61081486]\n",
      "Training Epoch [2/2]: 100%|█| 25/25 [07:15<00:00, 17.41s/it, curr_train_loss=738.76972840, val_loss=\n",
      "Validation Epoch [2/2]: 100%|██████████████████| 22/22 [01:44<00:00,  4.74s/it, val_loss=1.61107863]\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "print(device)\n",
    "train_model(model, trainer, train_dataset, val_dataset, epochs=2, device=device)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
